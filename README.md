# ğŸ§  Projet Final â€” DÃ©tection dâ€™Anomalies sur le Dataset MVTec AD

## ğŸ¯ Objectif du projet
Lâ€™objectif de ce projet est de **dÃ©tecter automatiquement les anomalies visuelles** dans des images industrielles issues du **dataset MVTec AD**.  
Chaque catÃ©gorie (bottle, cable, hazelnut, etc.) contient des images **normales** et **dÃ©fectueuses**.  
Le but est dâ€™entraÃ®ner et de comparer plusieurs mÃ©thodes afin dâ€™identifier les anomalies sans supervision directe.

ğŸ‘‰ Le travail a Ã©tÃ© rÃ©alisÃ© sur **toutes les catÃ©gories** du dataset MVTec AD, conformÃ©ment aux consignes du projet.

---

## ğŸ’» PrÃ©requis

Avant dâ€™exÃ©cuter le projet, il faut installer les outils suivants :

- Python 3.10 ou supÃ©rieur  
- PyTorch  
- scikit-learn  
- matplotlib  
- numpy, pandas  

Et tÃ©lÃ©charger jeu de donnÃ©e via ce lien :
 https://www.mvtec.com/company/research/datasets/mvtec-ad

 
### Installation rapide :
pip install -r requirements.txt
ğŸ“ Structure du projet
text
Copier le code
machine_learning/
â”œâ”€â”€ data/                      # Dataset MVTec AD (toutes les catÃ©gories)
â”‚   â”œâ”€â”€ bottle/
â”‚   â”œâ”€â”€ cable/
â”‚   â”œâ”€â”€ capsule/
â”‚   â”œâ”€â”€ hazelnut/
â”‚   â”œâ”€â”€ metal_nut/
â”‚   â”œâ”€â”€ pill/
â”‚   â”œâ”€â”€ screw/
â”‚   â”œâ”€â”€ toothbrush/
â”‚   â”œâ”€â”€ transistor/
â”‚   â”œâ”€â”€ wood/
â”‚   â””â”€â”€ zipper/
â”‚
â”œâ”€â”€ src/                       # Code source du projet
â”‚   â”œâ”€â”€ data/                  # Chargement et gestion des images
â”‚   â”œâ”€â”€ models/                # ModÃ¨les (Autoencoder)
â”‚   â”œâ”€â”€ methods/               # MÃ©thodes kNN et reconstruction AE
â”‚   â””â”€â”€ utils/                 # Fonctions utilitaires
â”‚
â”œâ”€â”€ scripts/                   # Scripts exÃ©cutables
â”‚   â”œâ”€â”€ visualize_examples.py
â”‚   â”œâ”€â”€ fit_knn.py / eval_knn.py
â”‚   â”œâ”€â”€ eval_ae.py / repeat_ae.py
â”‚   â”œâ”€â”€ compare_methods.py / merge_results.py / plot_final.py
â”‚   â”œâ”€â”€ visualize_heatmaps.py
â”‚   â””â”€â”€ eval_final.py
â”‚
â”œâ”€â”€ artifacts/                 # RÃ©sultats gÃ©nÃ©rÃ©s automatiquement
â”‚   â”œâ”€â”€ bottle/
â”‚   â”œâ”€â”€ cable/
â”‚   â”œâ”€â”€ hazelnut/
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ summary_compare.csv
â”‚   â”œâ”€â”€ final_auroc_barplot.png
â”‚   â””â”€â”€ final_summary.csv
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ§© Ã‰tape A â€” Visualisation du dataset
Afficher quelques exemples dâ€™images normales et dÃ©fectueuses :

py scripts/visualize_examples.py --data_root "data" --category bottle
â¡ï¸ Cette Ã©tape permet de comprendre la structure des donnÃ©es et dâ€™observer les diffÃ©rences visuelles entre les images normales et les anomalies.

âš™ï¸ Ã‰tape B â€” MÃ©thode 1 : kNN sur features prÃ©-entraÃ®nÃ©es
EntraÃ®nement :

py scripts/fit_knn.py --data_root "data" --category bottle
Ã‰valuation :


py scripts/eval_knn.py --data_root "data" --category bottle
â¡ï¸ RÃ©pÃ©ter pour toutes les catÃ©gories :



py scripts/fit_knn.py --data_root "data" --category cable
py scripts/fit_knn.py --data_root "data" --category hazelnut
...
ğŸ“„ RÃ©sultats :

Fichier : artifacts/<cat>/results_eval.csv

Contient les labels, scores et mÃ©triques de test.

ğŸ§  Ã‰tape C â€” MÃ©thode 2 : Autoencoder (AE)
EntraÃ®nement et Ã©valuation :


py scripts/eval_ae.py --data_root "data" --category bottle
â¡ï¸ RÃ©pÃ©ter pour toutes les catÃ©gories :



py scripts/eval_ae.py --data_root "data" --category cable
py scripts/eval_ae.py --data_root "data" --category hazelnut
...
VÃ©rification de la stabilitÃ© :


py scripts/repeat_ae.py --data_root "data" --categories bottle cable hazelnut metal_nut pill screw toothbrush transistor wood zipper --seeds 0 1 2 3 4 --epochs 10
ğŸ“„ RÃ©sultats :

summary_ae_multiseed.csv â†’ Moyenne Â± Ã©cart-type

ae_heatmaps/ â†’ visualisation des reconstructions

ğŸ“Š Ã‰tape D â€” Comparaison des mÃ©thodes (kNN vs AE)
Comparer les performances sur toutes les catÃ©gories :



py scripts.compare_methods --save_roc
py scripts.merge_results
py scripts.plot_final
ğŸ“ˆ Sorties :

summary_compare.csv

final_auroc_barplot.png (comparaison graphique des AUROC)

final_summary.csv

ğŸ”¥ Ã‰tape E â€” Visualisation qualitative
Afficher les zones dâ€™anomalies dÃ©tectÃ©es (heatmaps) :



py scripts.visualize_heatmaps --category bottle
â¡ï¸ RÃ©pÃ©ter pour dâ€™autres catÃ©gories :


py scripts.visualize_heatmaps --category cable
py scripts.visualize_heatmaps --category hazelnut
...
Ces cartes de chaleur montrent oÃ¹ le modÃ¨le dÃ©tecte les anomalies dans les images.

âœ… Ã‰tape F â€” Ã‰valuation finale
Ã‰valuer les performances finales du modÃ¨le choisi :



# Autoencoder
py scripts.eval_final --category bottle --method ae

# kNN
py scripts.eval_final --category bottle --method knn
â¡ï¸ RÃ©pÃ©ter pour toutes les catÃ©gories :



py scripts.eval_final --category cable --method ae
py scripts.eval_final --category hazelnut --method ae
...
ğŸ“Š Fichiers gÃ©nÃ©rÃ©s :

roc_ae.png, pr_ae.png, confmat_ae.png

top_ae.png, faux_positifs.png, faux_nÃ©gatifs.png

final_report_ae.csv â†’ rapport complet avec mÃ©triques et figures

ğŸ“ˆ InterprÃ©tation des rÃ©sultats
CatÃ©gorie	MÃ©thode	AUROC	AP	Accuracy	F1	Commentaire
Bottle	AE	~0.97	~0.95	0.93	0.91	TrÃ¨s bonne reconstruction
Cable	kNN	~0.85	~0.80	0.86	0.82	MÃ©thode simple mais stable
Hazelnut	AE	~0.98	~0.96	0.94	0.93	Haute prÃ©cision
...	...	...	...	...	...	...

ğŸ§© Ces valeurs peuvent lÃ©gÃ¨rement varier selon les seeds ou les paramÃ¨tres dâ€™entraÃ®nement.

ğŸ§  Points importants Ã  retenir
Les modÃ¨les sont entraÃ®nÃ©s uniquement sur les images normales (train/good).

Les images dÃ©fectueuses ne sont utilisÃ©es quâ€™en phase de test.

Les mÃ©triques principales :

AUROC : Aire sous la courbe ROC (mesure de la qualitÃ© du classement)

AP : Average Precision (Ã©quilibre prÃ©cision/rappel)

Accuracy et F1-score : qualitÃ© de la classification finale

Tous les rÃ©sultats et figures sont enregistrÃ©s automatiquement dans artifacts/.

ğŸ’¡ Conclusion
Ce projet dÃ©montre :

la prÃ©paration et le traitement dâ€™un dataset industriel dâ€™anomalies visuelles (MVTec AD),

la comparaison entre deux approches :

une mÃ©thode simple et robuste (kNN),

une mÃ©thode neurale non supervisÃ©e (Autoencoder),

lâ€™importance de lâ€™Ã©valuation multi-catÃ©gorie et multi-initialisation,

la capacitÃ© Ã  visualiser et interprÃ©ter les anomalies dÃ©tectÃ©es.

Les scripts fournis garantissent une reproductibilitÃ© complÃ¨te et une analyse rigoureuse des performances sur toutes les catÃ©gories du dataset.
